{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvYw54WpM8VL",
        "outputId": "55376131-b0fd-4fa0-a910-847d51ff1f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.5)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.72.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.65)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.65->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai langgraph PyPDF2 python-dotenv\n",
        "!pip install langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "import json\n",
        "import io\n",
        "from typing import List, Dict, Any, Optional\n",
        "from google.colab import userdata, files\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import HumanMessage\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "# Add your Gemini API key to Colab secrets with name 'GEMINI_API_KEY'\n",
        "try:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA7AYprgkC_DG31Fxjt7vY6Z1J8M2W1KwU\"\n",
        "    print(\"‚úÖ API key loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Please add your Gemini API key to Colab secrets with name 'GEMINI_API_KEY'\")\n",
        "    print(\"Go to the key icon on the left sidebar and add your key\")\n",
        "\n",
        "# Initialize Gemini model\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.3,\n",
        "    max_tokens=3000\n",
        ")\n"
      ],
      "metadata": {
        "id": "xszAuP_tN-Bz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccec387e-3263-407b-8fbe-bc8361b8f22d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API key loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFQuizState(TypedDict):\n",
        "    \"\"\"State schema for PDF quiz generation workflow\"\"\"\n",
        "    pdf_content: str\n",
        "    summary: str\n",
        "    quiz_questions: List[Dict[str, Any]]\n",
        "    current_step: str\n",
        "    error_message: Optional[str]\n",
        "    file_name: str"
      ],
      "metadata": {
        "id": "b2kBmpmkOkIt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFProcessor:\n",
        "    \"\"\"Handles PDF file processing and content extraction\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def upload_pdf() -> tuple[str, str]:\n",
        "        \"\"\"Upload PDF file in Colab and return path and filename\"\"\"\n",
        "        print(\"üìÅ Please upload your PDF file:\")\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            raise ValueError(\"No file uploaded\")\n",
        "\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        if not filename.lower().endswith('.pdf'):\n",
        "            raise ValueError(\"Please upload a PDF file\")\n",
        "\n",
        "        print(f\"‚úÖ Uploaded: {filename}\")\n",
        "        return filename, filename\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_pdf_content(pdf_path: str) -> str:\n",
        "        \"\"\"Extract text content from PDF file\"\"\"\n",
        "        try:\n",
        "            with open(pdf_path, \"rb\") as file:\n",
        "                reader = PyPDF2.PdfReader(file)\n",
        "                content = \"\"\n",
        "\n",
        "                print(f\"üìñ Processing {len(reader.pages)} pages...\")\n",
        "\n",
        "                for page_num, page in enumerate(reader.pages, 1):\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text.strip():  # Only add non-empty pages\n",
        "                        content += f\"\\n--- Page {page_num} ---\\n\"\n",
        "                        content += page_text + \"\\n\"\n",
        "\n",
        "                if not content.strip():\n",
        "                    raise ValueError(\"No text content found in PDF\")\n",
        "\n",
        "                print(f\"‚úÖ Extracted {len(content)} characters from PDF\")\n",
        "                return content.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error extracting PDF content: {str(e)}\")"
      ],
      "metadata": {
        "id": "w_wTC2_xOpmJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_content(state: PDFQuizState) -> PDFQuizState:\n",
        "    \"\"\"Node to load and process PDF content\"\"\"\n",
        "    try:\n",
        "        # If pdf_content is already loaded, skip this step\n",
        "        if state.get(\"pdf_content\"):\n",
        "            state[\"current_step\"] = \"content_loaded\"\n",
        "            return state\n",
        "\n",
        "        # This would be called with pre-loaded content\n",
        "        state[\"current_step\"] = \"content_loaded\"\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        state[\"error_message\"] = f\"PDF loading error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "\n",
        "def summarize_pdf_content(state: PDFQuizState) -> PDFQuizState:\n",
        "    \"\"\"Node to summarize PDF content into key points\"\"\"\n",
        "\n",
        "    summary_prompt = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        You are an expert educational content summarizer analyzing a PDF document.\n",
        "\n",
        "        Please analyze the following content from a PDF and create a comprehensive summary:\n",
        "\n",
        "        PDF Content:\n",
        "        {content}\n",
        "\n",
        "        Instructions:\n",
        "        - Create 6-10 clear, concise bullet points that capture the most important concepts\n",
        "        - Focus on key facts, definitions, processes, and main ideas\n",
        "        - Each bullet point should be specific and informative\n",
        "        - Organize points logically from general to specific concepts\n",
        "        - Use educational language appropriate for quiz generation\n",
        "        - Ignore any formatting artifacts or page numbers\n",
        "\n",
        "        Provide only the bullet-point summary:\n",
        "        \"\"\",\n",
        "        input_variables=[\"content\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Generating summary from PDF content...\")\n",
        "\n",
        "        # Truncate content if too long (Gemini has token limits)\n",
        "        content = state[\"pdf_content\"]\n",
        "        if len(content) > 15000:  # Approximate token limit consideration\n",
        "            print(\"‚ö†Ô∏è  PDF content is long, using first 15000 characters\")\n",
        "            content = content[:15000] + \"... [content truncated]\"\n",
        "\n",
        "        prompt_text = summary_prompt.format(content=content)\n",
        "        response = llm.invoke([HumanMessage(content=prompt_text)])\n",
        "\n",
        "        state[\"summary\"] = response.content\n",
        "        state[\"current_step\"] = \"summarization_complete\"\n",
        "        print(\"‚úÖ Summary generated successfully\")\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"error_message\"] = f\"Summarization error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "\n",
        "def generate_pdf_quiz(state: PDFQuizState) -> PDFQuizState:\n",
        "    \"\"\"Node to generate quiz questions from PDF summary\"\"\"\n",
        "\n",
        "    quiz_prompt = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        You are an expert quiz creator. Based on the following summary from a PDF document,\n",
        "        create exactly 6 high-quality multiple-choice questions.\n",
        "\n",
        "        Summary from PDF:\n",
        "        {summary}\n",
        "\n",
        "        Requirements:\n",
        "        - Create exactly 6 questions that test understanding of key concepts\n",
        "        - Each question must have exactly 4 options (a, b, c, d)\n",
        "        - Only one correct answer per question\n",
        "        - Make incorrect options plausible but clearly wrong\n",
        "        - Questions should test comprehension, not just memorization\n",
        "        - Include a brief explanation for each correct answer\n",
        "\n",
        "        Format your response as valid JSON with this exact structure:\n",
        "        {{\n",
        "            \"questions\": [\n",
        "                {{\n",
        "                    \"question\": \"Clear, specific question text?\",\n",
        "                    \"options\": {{\n",
        "                        \"a\": \"First option text\",\n",
        "                        \"b\": \"Second option text\",\n",
        "                        \"c\": \"Third option text\",\n",
        "                        \"d\": \"Fourth option text\"\n",
        "                    }},\n",
        "                    \"correct_answer\": \"a\",\n",
        "                    \"explanation\": \"Clear explanation of why this answer is correct\"\n",
        "                }}\n",
        "            ]\n",
        "        }}\n",
        "\n",
        "        Generate the 6 quiz questions now:\n",
        "        \"\"\",\n",
        "        input_variables=[\"summary\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Generating quiz questions...\")\n",
        "\n",
        "        prompt_text = quiz_prompt.format(summary=state[\"summary\"])\n",
        "        response = llm.invoke([HumanMessage(content=prompt_text)])\n",
        "\n",
        "        # Clean the response content to ensure valid JSON\n",
        "        response_content = response.content.strip()\n",
        "\n",
        "        # Remove markdown code blocks if present\n",
        "        if response_content.startswith(\"```json\"):\n",
        "            response_content = response_content[7:]\n",
        "        if response_content.endswith(\"```\"):\n",
        "            response_content = response_content[:-3]\n",
        "\n",
        "        # Parse JSON response\n",
        "        quiz_data = json.loads(response_content.strip())\n",
        "\n",
        "        if \"questions\" not in quiz_data or len(quiz_data[\"questions\"]) == 0:\n",
        "            raise ValueError(\"No questions generated in response\")\n",
        "\n",
        "        state[\"quiz_questions\"] = quiz_data[\"questions\"]\n",
        "        state[\"current_step\"] = \"quiz_complete\"\n",
        "        print(f\"‚úÖ Generated {len(quiz_data['questions'])} quiz questions\")\n",
        "        return state\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        state[\"error_message\"] = f\"JSON parsing error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        state[\"error_message\"] = f\"Quiz generation error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "\n",
        "# Step 7: Create LangGraph Workflow\n",
        "def create_pdf_quiz_workflow():\n",
        "    \"\"\"Create the PDF quiz generation workflow using LangGraph\"\"\"\n",
        "\n",
        "    workflow = StateGraph(PDFQuizState)\n",
        "\n",
        "    # Add processing nodes\n",
        "    workflow.add_node(\"load_content\", load_pdf_content)\n",
        "    workflow.add_node(\"summarize\", summarize_pdf_content)\n",
        "    workflow.add_node(\"generate_quiz\", generate_pdf_quiz)\n",
        "\n",
        "    # Define the workflow path\n",
        "    workflow.set_entry_point(\"load_content\")\n",
        "    workflow.add_edge(\"load_content\", \"summarize\")\n",
        "    workflow.add_edge(\"summarize\", \"generate_quiz\")\n",
        "    workflow.add_edge(\"generate_quiz\", END)\n",
        "\n",
        "    # Compile the workflow\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "tBBFVYMHOum6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_content(state: PDFQuizState) -> PDFQuizState:\n",
        "    \"\"\"Node to load and process PDF content\"\"\"\n",
        "    try:\n",
        "        # If pdf_content is already loaded, skip this step\n",
        "        if state.get(\"pdf_content\"):\n",
        "            state[\"current_step\"] = \"content_loaded\"\n",
        "            return state\n",
        "\n",
        "        # This would be called with pre-loaded content\n",
        "        state[\"current_step\"] = \"content_loaded\"\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        state[\"error_message\"] = f\"PDF loading error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "\n",
        "def summarize_pdf_content(state: PDFQuizState) -> PDFQuizState:\n",
        "    \"\"\"Node to summarize PDF content into key points\"\"\"\n",
        "\n",
        "    summary_prompt = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        You are an expert educational content summarizer analyzing a PDF document.\n",
        "\n",
        "        Please analyze the following content from a PDF and create a comprehensive summary:\n",
        "\n",
        "        PDF Content:\n",
        "        {content}\n",
        "\n",
        "        Instructions:\n",
        "        - Create 6-10 clear, concise bullet points that capture the most important concepts\n",
        "        - Focus on key facts, definitions, processes, and main ideas\n",
        "        - Each bullet point should be specific and informative\n",
        "        - Organize points logically from general to specific concepts\n",
        "        - Use educational language appropriate for quiz generation\n",
        "        - Ignore any formatting artifacts or page numbers\n",
        "\n",
        "        Provide only the bullet-point summary:\n",
        "        \"\"\",\n",
        "        input_variables=[\"content\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Generating summary from PDF content...\")\n",
        "\n",
        "        # Truncate content if too long (Gemini has token limits)\n",
        "        content = state[\"pdf_content\"]\n",
        "        if len(content) > 15000:  # Approximate token limit consideration\n",
        "            print(\"‚ö†Ô∏è  PDF content is long, using first 15000 characters\")\n",
        "            content = content[:15000] + \"... [content truncated]\"\n",
        "\n",
        "        prompt_text = summary_prompt.format(content=content)\n",
        "        response = llm.invoke([HumanMessage(content=prompt_text)])\n",
        "\n",
        "        state[\"summary\"] = response.content\n",
        "        state[\"current_step\"] = \"summarization_complete\"\n",
        "        print(\"‚úÖ Summary generated successfully\")\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"error_message\"] = f\"Summarization error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "\n",
        "def generate_pdf_quiz(state: PDFQuizState) -> PDFQuizState:\n",
        "    \"\"\"Node to generate quiz questions from PDF summary\"\"\"\n",
        "\n",
        "    quiz_prompt = PromptTemplate(\n",
        "        template=\"\"\"\n",
        "        You are an expert quiz creator. Based on the following summary from a PDF document,\n",
        "        create exactly 6 high-quality multiple-choice questions.\n",
        "\n",
        "        Summary from PDF:\n",
        "        {summary}\n",
        "\n",
        "        Requirements:\n",
        "        - Create exactly 6 questions that test understanding of key concepts\n",
        "        - Each question must have exactly 4 options (a, b, c, d)\n",
        "        - Only one correct answer per question\n",
        "        - Make incorrect options plausible but clearly wrong\n",
        "        - Questions should test comprehension, not just memorization\n",
        "        - Include a brief explanation for each correct answer\n",
        "\n",
        "        Format your response as valid JSON with this exact structure:\n",
        "        {{\n",
        "            \"questions\": [\n",
        "                {{\n",
        "                    \"question\": \"Clear, specific question text?\",\n",
        "                    \"options\": {{\n",
        "                        \"a\": \"First option text\",\n",
        "                        \"b\": \"Second option text\",\n",
        "                        \"c\": \"Third option text\",\n",
        "                        \"d\": \"Fourth option text\"\n",
        "                    }},\n",
        "                    \"correct_answer\": \"a\",\n",
        "                    \"explanation\": \"Clear explanation of why this answer is correct\"\n",
        "                }}\n",
        "            ]\n",
        "        }}\n",
        "\n",
        "        Generate the 6 quiz questions now:\n",
        "        \"\"\",\n",
        "        input_variables=[\"summary\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Generating quiz questions...\")\n",
        "\n",
        "        prompt_text = quiz_prompt.format(summary=state[\"summary\"])\n",
        "        response = llm.invoke([HumanMessage(content=prompt_text)])\n",
        "\n",
        "        # Clean the response content to ensure valid JSON\n",
        "        response_content = response.content.strip()\n",
        "\n",
        "        # Remove markdown code blocks if present\n",
        "        if response_content.startswith(\"```json\"):\n",
        "            response_content = response_content[7:]\n",
        "        if response_content.endswith(\"```\"):\n",
        "            response_content = response_content[:-3]\n",
        "\n",
        "        # Parse JSON response\n",
        "        quiz_data = json.loads(response_content.strip())\n",
        "\n",
        "        if \"questions\" not in quiz_data or len(quiz_data[\"questions\"]) == 0:\n",
        "            raise ValueError(\"No questions generated in response\")\n",
        "\n",
        "        state[\"quiz_questions\"] = quiz_data[\"questions\"]\n",
        "        state[\"current_step\"] = \"quiz_complete\"\n",
        "        print(f\"‚úÖ Generated {len(quiz_data['questions'])} quiz questions\")\n",
        "        return state\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        state[\"error_message\"] = f\"JSON parsing error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        state[\"error_message\"] = f\"Quiz generation error: {str(e)}\"\n",
        "        state[\"current_step\"] = \"error\"\n",
        "        return state"
      ],
      "metadata": {
        "id": "Uc03M58wOyYR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Create LangGraph Workflow\n",
        "def create_pdf_quiz_workflow():\n",
        "    \"\"\"Create the PDF quiz generation workflow using LangGraph\"\"\"\n",
        "\n",
        "    workflow = StateGraph(PDFQuizState)\n",
        "\n",
        "    # Add processing nodes\n",
        "    workflow.add_node(\"load_content\", load_pdf_content)\n",
        "    workflow.add_node(\"summarize\", summarize_pdf_content)\n",
        "    workflow.add_node(\"generate_quiz\", generate_pdf_quiz)\n",
        "\n",
        "    # Define the workflow path\n",
        "    workflow.set_entry_point(\"load_content\")\n",
        "    workflow.add_edge(\"load_content\", \"summarize\")\n",
        "    workflow.add_edge(\"summarize\", \"generate_quiz\")\n",
        "    workflow.add_edge(\"generate_quiz\", END)\n",
        "\n",
        "    # Compile the workflow\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "SHYZtVvBO2jN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PDFQuizGenerator:\n",
        "    \"\"\"Main class for generating quizzes from PDF files\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.workflow = create_pdf_quiz_workflow()\n",
        "        self.processor = PDFProcessor()\n",
        "\n",
        "    def generate_quiz_from_upload(self) -> Dict[str, Any]:\n",
        "        \"\"\"Upload PDF and generate quiz\"\"\"\n",
        "        try:\n",
        "            # Upload PDF file\n",
        "            filename, filepath = self.processor.upload_pdf()\n",
        "\n",
        "            # Extract content\n",
        "            content = self.processor.extract_pdf_content(filepath)\n",
        "\n",
        "            # Process through workflow\n",
        "            return self._process_pdf_content(content, filename)\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"summary\": \"\",\n",
        "                \"quiz_questions\": [],\n",
        "                \"error\": str(e),\n",
        "                \"file_name\": \"\"\n",
        "            }\n",
        "\n",
        "    def generate_quiz_from_path(self, pdf_path: str) -> Dict[str, Any]:\n",
        "        \"\"\"Generate quiz from existing PDF path\"\"\"\n",
        "        try:\n",
        "            filename = pdf_path.split('/')[-1]\n",
        "            content = self.processor.extract_pdf_content(pdf_path)\n",
        "            return self._process_pdf_content(content, filename)\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"summary\": \"\",\n",
        "                \"quiz_questions\": [],\n",
        "                \"error\": str(e),\n",
        "                \"file_name\": pdf_path.split('/')[-1] if '/' in pdf_path else pdf_path\n",
        "            }\n",
        "\n",
        "    def _process_pdf_content(self, content: str, filename: str) -> Dict[str, Any]:\n",
        "        \"\"\"Process PDF content through the workflow\"\"\"\n",
        "\n",
        "        # Initialize state\n",
        "        initial_state = {\n",
        "            \"pdf_content\": content,\n",
        "            \"summary\": \"\",\n",
        "            \"quiz_questions\": [],\n",
        "            \"current_step\": \"initialized\",\n",
        "            \"error_message\": None,\n",
        "            \"file_name\": filename\n",
        "        }\n",
        "\n",
        "        # Run workflow\n",
        "        try:\n",
        "            print(f\"üöÄ Processing {filename} through workflow...\")\n",
        "            result = self.workflow.invoke(initial_state)\n",
        "\n",
        "            if result.get(\"error_message\"):\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"summary\": result.get(\"summary\", \"\"),\n",
        "                    \"quiz_questions\": result.get(\"quiz_questions\", []),\n",
        "                    \"error\": result[\"error_message\"],\n",
        "                    \"file_name\": filename\n",
        "                }\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"summary\": result[\"summary\"],\n",
        "                \"quiz_questions\": result[\"quiz_questions\"],\n",
        "                \"error\": \"\",\n",
        "                \"file_name\": filename\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"summary\": \"\",\n",
        "                \"quiz_questions\": [],\n",
        "                \"error\": str(e),\n",
        "                \"file_name\": filename\n",
        "            }\n",
        "\n",
        "    def display_results(self, result: Dict[str, Any]):\n",
        "        \"\"\"Display quiz results in formatted way\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"üìÑ PDF QUIZ GENERATOR RESULTS\")\n",
        "        print(f\"üìÅ File: {result['file_name']}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        if not result[\"success\"]:\n",
        "            print(f\"‚ùå Error: {result['error']}\")\n",
        "            return\n",
        "\n",
        "        # Display summary\n",
        "        print(\"\\nüìã CONTENT SUMMARY:\")\n",
        "        print(\"-\" * 40)\n",
        "        print(result[\"summary\"])\n",
        "\n",
        "        # Display quiz questions\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"‚ùì QUIZ QUESTIONS\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        for i, question in enumerate(result[\"quiz_questions\"], 1):\n",
        "            print(f\"\\nQuestion {i}: {question['question']}\")\n",
        "            print()\n",
        "            for option_key, option_text in question[\"options\"].items():\n",
        "                marker = \"‚úì\" if option_key == question[\"correct_answer\"] else \" \"\n",
        "                print(f\"   {option_key}) {option_text} {marker}\")\n",
        "\n",
        "            print(f\"\\n   üí° Explanation: {question['explanation']}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        print(f\"\\n‚úÖ Generated {len(result['quiz_questions'])} questions from PDF\")\n"
      ],
      "metadata": {
        "id": "Ozmvl-NeO7Yy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_interactive_quiz(quiz_questions: List[Dict[str, Any]], file_name: str = \"\"):\n",
        "    \"\"\"Run an interactive quiz session\"\"\"\n",
        "    if not quiz_questions:\n",
        "        print(\"‚ùå No quiz questions available\")\n",
        "        return\n",
        "\n",
        "    score = 0\n",
        "    total_questions = len(quiz_questions)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"üéØ INTERACTIVE QUIZ MODE\")\n",
        "    if file_name:\n",
        "        print(f\"üìÅ Source: {file_name}\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Instructions: Type a, b, c, or d for each question\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for i, question in enumerate(quiz_questions, 1):\n",
        "        print(f\"\\nQuestion {i}/{total_questions}: {question['question']}\")\n",
        "        print()\n",
        "\n",
        "        for option_key, option_text in question[\"options\"].items():\n",
        "            print(f\"   {option_key}) {option_text}\")\n",
        "\n",
        "        # Get user input\n",
        "        while True:\n",
        "            user_answer = input(f\"\\nYour answer (a/b/c/d): \").lower().strip()\n",
        "            if user_answer in ['a', 'b', 'c', 'd']:\n",
        "                break\n",
        "            print(\"Please enter a, b, c, or d\")\n",
        "\n",
        "        # Check answer\n",
        "        if user_answer == question[\"correct_answer\"]:\n",
        "            print(\"‚úÖ Correct!\")\n",
        "            score += 1\n",
        "        else:\n",
        "            print(f\"‚ùå Incorrect. The correct answer is: {question['correct_answer']}\")\n",
        "\n",
        "        print(f\"üí° {question['explanation']}\")\n",
        "\n",
        "        if i < total_questions:\n",
        "            input(\"\\nPress Enter to continue...\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "    # Final score\n",
        "    percentage = (score / total_questions) * 100\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"üèÜ QUIZ COMPLETED!\")\n",
        "    print(f\"üìä Final Score: {score}/{total_questions} ({percentage:.1f}%)\")\n",
        "\n",
        "    if percentage >= 80:\n",
        "        print(\"üåü Excellent work!\")\n",
        "    elif percentage >= 60:\n",
        "        print(\"üëç Good job!\")\n",
        "    else:\n",
        "        print(\"üìö Keep studying!\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "4CU981DlSzhq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main function to run the PDF quiz generator\"\"\"\n",
        "    print(\"üéì PDF Quiz Generator\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = PDFQuizGenerator()\n",
        "\n",
        "    # Choose input method\n",
        "    print(\"\\nChoose an option:\")\n",
        "    print(\"1. Upload a new PDF file\")\n",
        "    print(\"2. Use existing PDF file path\")\n",
        "\n",
        "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Upload and process new PDF\n",
        "        result = generator.generate_quiz_from_upload()\n",
        "    elif choice == \"2\":\n",
        "        # Use existing PDF path\n",
        "        pdf_path = input(\"Enter PDF file path: \").strip()\n",
        "        result = generator.generate_quiz_from_path(pdf_path)\n",
        "    else:\n",
        "        print(\"Invalid choice\")\n",
        "        return\n",
        "\n",
        "    # Display results\n",
        "    generator.display_results(result)\n",
        "\n",
        "    # Ask if user wants interactive quiz\n",
        "    if result[\"success\"] and result[\"quiz_questions\"]:\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        interactive = input(\"Would you like to take the interactive quiz? (y/n): \").lower().strip()\n",
        "        if interactive == 'y':\n",
        "            run_interactive_quiz(result[\"quiz_questions\"], result[\"file_name\"])"
      ],
      "metadata": {
        "id": "AAJymPP8S3On"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_test():\n",
        "    \"\"\"Quick test function\"\"\"\n",
        "    print(\"üß™ Quick Test Mode\")\n",
        "    generator = PDFQuizGenerator()\n",
        "\n",
        "    # For testing, you can create a sample PDF or use existing one\n",
        "    # This is just to show the structure\n",
        "    sample_content = \"\"\"\n",
        "    Artificial Intelligence (AI) is a branch of computer science that aims to create intelligent machines that can perform tasks that typically require human intelligence. Machine Learning is a subset of AI that enables computers to learn and improve from experience without being explicitly programmed. Deep Learning is a subset of machine learning that uses neural networks with multiple layers to analyze and learn from data. Natural Language Processing (NLP) is a field of AI that focuses on the interaction between computers and human language, enabling machines to understand, interpret, and generate human language.\n",
        "    \"\"\"\n",
        "\n",
        "    # Simulate processing\n",
        "    result = generator._process_pdf_content(sample_content, \"sample_ai_document.pdf\")\n",
        "    generator.display_results(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ Starting PDF Quiz Generator...\")\n",
        "    print(\"Make sure you have added your Gemini API key to Colab secrets!\")\n",
        "\n",
        "    # Uncomment the line below to run the main program\n",
        "    main()\n",
        "\n",
        "    # Uncomment the line below to run quick test\n",
        "    # quick_test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubSkiQWgS-2w",
        "outputId": "de1021c0-8460-4cd5-bd35-723ed309d193"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting PDF Quiz Generator...\n",
            "Make sure you have added your Gemini API key to Colab secrets!\n",
            "üéì PDF Quiz Generator\n",
            "========================================\n",
            "\n",
            "Choose an option:\n",
            "1. Upload a new PDF file\n",
            "2. Use existing PDF file path\n",
            "Enter choice (1 or 2): 2\n",
            "Enter PDF file path: content/ai_in_education.pdf\n",
            "üìñ Processing 10 pages...\n",
            "‚úÖ Extracted 43379 characters from PDF\n",
            "üöÄ Processing ai_in_education.pdf through workflow...\n",
            "üîÑ Generating summary from PDF content...\n",
            "‚ö†Ô∏è  PDF content is long, using first 15000 characters\n",
            "‚úÖ Summary generated successfully\n",
            "üîÑ Generating quiz questions...\n",
            "‚úÖ Generated 6 quiz questions\n",
            "\n",
            "============================================================\n",
            "üìÑ PDF QUIZ GENERATOR RESULTS\n",
            "üìÅ File: ai_in_education.pdf\n",
            "============================================================\n",
            "\n",
            "üìã CONTENT SUMMARY:\n",
            "----------------------------------------\n",
            "* This phenomenological study investigated the implications of Artificial Intelligence (AI) in education, gathering perspectives from academics, legal experts, engineers, and teachers.\n",
            "\n",
            "* AI in education is defined as the use of computer systems to mimic human thought processes and actions to enhance learning.  The study explores the potential for AI to revolutionize education, similar to electricity's impact on previous industrial revolutions.\n",
            "\n",
            "* The study utilized semi-structured interviews and content analysis to analyze participants' perceptions of AI's role in education, focusing on potential benefits and drawbacks.\n",
            "\n",
            "* Participants generally held positive views towards AI's potential to personalize learning, improve accessibility for marginalized groups, and reduce teacher workload. However, concerns were raised regarding AI's potential to replace teachers and ethical considerations.\n",
            "\n",
            "*  Different professional groups held varying perspectives: teachers and academics emphasized the potential impact on the teaching profession; legal experts focused on the legal implications; and engineers viewed AI as a tool for improving educational quality.\n",
            "\n",
            "* The research methodology employed purposeful sampling, data triangulation (using multiple data sources and perspectives), and analyst triangulation (multiple researchers analyzing the data) to ensure trustworthiness and rigor.\n",
            "\n",
            "* Key findings highlighted the potential for AI to individualize instruction, improve learning experiences, and enhance creativity; however, concerns about the potential displacement of teachers and the need for ethical guidelines were also identified.\n",
            "\n",
            "* The study concludes with suggestions for utilizing AI effectively in education while mitigating potential negative consequences, emphasizing the importance of a balanced approach that leverages technology while preserving the human element of teaching.\n",
            "\n",
            "============================================================\n",
            "‚ùì QUIZ QUESTIONS\n",
            "============================================================\n",
            "\n",
            "Question 1: What research methodology was NOT explicitly mentioned in the study summary as contributing to the trustworthiness and rigor of the findings?\n",
            "\n",
            "   a) Purposeful sampling  \n",
            "   b) Random sampling ‚úì\n",
            "   c) Data triangulation  \n",
            "   d) Analyst triangulation  \n",
            "\n",
            "   üí° Explanation: The summary explicitly states the use of purposeful sampling, data triangulation, and analyst triangulation. Random sampling is not mentioned and would be inappropriate for this qualitative study focusing on specific perspectives.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question 2: Which of the following BEST describes the central research question of the phenomenological study?\n",
            "\n",
            "   a) How can AI completely replace teachers in the classroom?  \n",
            "   b) What are the ethical implications of using AI in education?  \n",
            "   c) What are the implications of using AI in education, considering the perspectives of various stakeholders? ‚úì\n",
            "   d) How can AI improve standardized test scores?  \n",
            "\n",
            "   üí° Explanation: The summary highlights the study's aim to investigate the implications of AI in education from multiple perspectives (academics, legal experts, engineers, and teachers), making option C the most accurate reflection of the central research question.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question 3: According to the summary, which group primarily focused on the legal ramifications of AI in education?\n",
            "\n",
            "   a) Teachers  \n",
            "   b) Engineers  \n",
            "   c) Academics  \n",
            "   d) Legal experts ‚úì\n",
            "\n",
            "   üí° Explanation: The summary explicitly states that legal experts focused on the legal implications of AI in education.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question 4: The study's findings suggest that AI in education has the potential to:\n",
            "\n",
            "   a) Completely eliminate the need for human teachers.  \n",
            "   b) Improve learning experiences and enhance creativity, but also raises ethical concerns. ‚úì\n",
            "   c) Only benefit high-achieving students.  \n",
            "   d) Increase teacher workload significantly.  \n",
            "\n",
            "   üí° Explanation: The summary highlights both the positive potential (improved learning, enhanced creativity) and the negative concerns (ethical considerations, potential displacement of teachers) related to AI in education.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question 5: What analogy was used in the summary to illustrate the transformative potential of AI in education?\n",
            "\n",
            "   a) The impact of the internet on communication.  \n",
            "   b) The impact of the printing press on literacy.  \n",
            "   c) The impact of electricity on previous industrial revolutions. ‚úì\n",
            "   d) The impact of social media on social interaction.  \n",
            "\n",
            "   üí° Explanation: The summary directly compares the potential revolutionary impact of AI in education to that of electricity on previous industrial revolutions.\n",
            "--------------------------------------------------\n",
            "\n",
            "Question 6: The study's conclusion emphasizes the need for:\n",
            "\n",
            "   a) A complete rejection of AI in education.  \n",
            "   b) Unrestricted implementation of AI in education.  \n",
            "   c) A balanced approach that leverages technology while preserving the human element of teaching. ‚úì\n",
            "   d) Focusing solely on the technological aspects of AI implementation.  \n",
            "\n",
            "   üí° Explanation: The summary explicitly concludes with a call for a balanced approach that utilizes AI effectively while mitigating negative consequences and preserving the human aspect of teaching.\n",
            "--------------------------------------------------\n",
            "\n",
            "‚úÖ Generated 6 questions from PDF\n",
            "\n",
            "============================================================\n",
            "Would you like to take the interactive quiz? (y/n): y\n",
            "\n",
            "============================================================\n",
            "üéØ INTERACTIVE QUIZ MODE\n",
            "üìÅ Source: ai_in_education.pdf\n",
            "============================================================\n",
            "Instructions: Type a, b, c, or d for each question\n",
            "------------------------------------------------------------\n",
            "\n",
            "Question 1/6: What research methodology was NOT explicitly mentioned in the study summary as contributing to the trustworthiness and rigor of the findings?\n",
            "\n",
            "   a) Purposeful sampling\n",
            "   b) Random sampling\n",
            "   c) Data triangulation\n",
            "   d) Analyst triangulation\n",
            "\n",
            "Your answer (a/b/c/d): b\n",
            "‚úÖ Correct!\n",
            "üí° The summary explicitly states the use of purposeful sampling, data triangulation, and analyst triangulation. Random sampling is not mentioned and would be inappropriate for this qualitative study focusing on specific perspectives.\n",
            "\n",
            "Press Enter to continue...\n",
            "------------------------------------------------------------\n",
            "\n",
            "Question 2/6: Which of the following BEST describes the central research question of the phenomenological study?\n",
            "\n",
            "   a) How can AI completely replace teachers in the classroom?\n",
            "   b) What are the ethical implications of using AI in education?\n",
            "   c) What are the implications of using AI in education, considering the perspectives of various stakeholders?\n",
            "   d) How can AI improve standardized test scores?\n",
            "\n",
            "Your answer (a/b/c/d): c\n",
            "‚úÖ Correct!\n",
            "üí° The summary highlights the study's aim to investigate the implications of AI in education from multiple perspectives (academics, legal experts, engineers, and teachers), making option C the most accurate reflection of the central research question.\n",
            "\n",
            "Press Enter to continue...\n",
            "------------------------------------------------------------\n",
            "\n",
            "Question 3/6: According to the summary, which group primarily focused on the legal ramifications of AI in education?\n",
            "\n",
            "   a) Teachers\n",
            "   b) Engineers\n",
            "   c) Academics\n",
            "   d) Legal experts\n",
            "\n",
            "Your answer (a/b/c/d): d\n",
            "‚úÖ Correct!\n",
            "üí° The summary explicitly states that legal experts focused on the legal implications of AI in education.\n",
            "\n",
            "Press Enter to continue...\n",
            "------------------------------------------------------------\n",
            "\n",
            "Question 4/6: The study's findings suggest that AI in education has the potential to:\n",
            "\n",
            "   a) Completely eliminate the need for human teachers.\n",
            "   b) Improve learning experiences and enhance creativity, but also raises ethical concerns.\n",
            "   c) Only benefit high-achieving students.\n",
            "   d) Increase teacher workload significantly.\n",
            "\n",
            "Your answer (a/b/c/d): b\n",
            "‚úÖ Correct!\n",
            "üí° The summary highlights both the positive potential (improved learning, enhanced creativity) and the negative concerns (ethical considerations, potential displacement of teachers) related to AI in education.\n",
            "\n",
            "Press Enter to continue...\n",
            "------------------------------------------------------------\n",
            "\n",
            "Question 5/6: What analogy was used in the summary to illustrate the transformative potential of AI in education?\n",
            "\n",
            "   a) The impact of the internet on communication.\n",
            "   b) The impact of the printing press on literacy.\n",
            "   c) The impact of electricity on previous industrial revolutions.\n",
            "   d) The impact of social media on social interaction.\n",
            "\n",
            "Your answer (a/b/c/d): c\n",
            "‚úÖ Correct!\n",
            "üí° The summary directly compares the potential revolutionary impact of AI in education to that of electricity on previous industrial revolutions.\n",
            "\n",
            "Press Enter to continue...c\n",
            "------------------------------------------------------------\n",
            "\n",
            "Question 6/6: The study's conclusion emphasizes the need for:\n",
            "\n",
            "   a) A complete rejection of AI in education.\n",
            "   b) Unrestricted implementation of AI in education.\n",
            "   c) A balanced approach that leverages technology while preserving the human element of teaching.\n",
            "   d) Focusing solely on the technological aspects of AI implementation.\n",
            "\n",
            "Your answer (a/b/c/d): c\n",
            "‚úÖ Correct!\n",
            "üí° The summary explicitly concludes with a call for a balanced approach that utilizes AI effectively while mitigating negative consequences and preserving the human aspect of teaching.\n",
            "\n",
            "============================================================\n",
            "üèÜ QUIZ COMPLETED!\n",
            "üìä Final Score: 6/6 (100.0%)\n",
            "üåü Excellent work!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}